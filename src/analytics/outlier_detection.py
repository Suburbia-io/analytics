from datetime import timedelta
from multiprocessing import Pool

import numpy as np
import pandas as pd
from fbprophet import Prophet
from matplotlib import pyplot as plt


class Analyzer:
    def __init__(
        self, old_data, new_data, new_daterange, metadata, interval_multiplier=1.5
    ):
        self.old_data = old_data
        self.new_data = new_data
        self.new_daterange = new_daterange
        self.metadata = metadata
        self.interval_multiplier = interval_multiplier
        self.model = None
        self.deviations = None

    def find_deviations(self):
        self.model = make_model(self.old_data)
        predictions = self.model.predict(self.new_daterange)
        self.deviations = get_deviations(
            predictions, self.new_data, self.interval_multiplier
        )

    def check_deviations(self):
        if not isinstance(self.deviations, pd.DataFrame):
            raise ValueError("Deviations not computed")

    def make_chart(self):
        self.check_deviations()
        return create_chart(
            self.old_data, self.new_data, self.deviations, self.metadata
        )

    def get_filtered_deviations(self):
        self.check_deviations()
        return self.deviations.loc[lambda d: d["status"] != "ok"].assign(
            **self.metadata
        )[["ds", "metric", "dimension", "item", "status"]]

    def is_ok(self):
        self.check_deviations()
        n_lines_with_issues = len(self.deviations.loc[lambda d: d["status"] != "ok"])
        return n_lines_with_issues == 0

    def get_summary(self):
        return pd.DataFrame({**self.metadata, "ok": self.is_ok(),}, index=[0])


def find_new_outliers(
    data, reference_date, metrics, dimensions_items, dates_to_exclude=None,
):
    """
    Find outliers for selected metrics and dimensions/items

    :param data: Input data to check outliers for
    :param reference_date: Cutoff date for training set.
    Model will use 365 days prior to this date to train.
    :param metrics: List of metrics to compute outliers for
    :param dimensions_items: Dimensions and items to compute outliers for,
    provided in a dictionary where keys are dimensions and values are lists of items
    :param dates_to_exclude: List of dates to exclude from training, optional.
    Use this if dataset still includes period of incorrect data.
    :return: Dataframe of problematic observations.
    """
    dates_to_exclude = dates_to_exclude or []
    old_data, new_data = prepare(data, reference_date, dates_to_exclude)
    new_data_daterange = create_daterange_df(new_data)

    all_inputs = list()
    for metric in metrics:
        for dimension, items in dimensions_items.items():
            for item in items:
                if subset_exists(old_data, metric, dimension, item):
                    filters = {
                        "metric": metric,
                        "dimension": dimension,
                        "item": item,
                    }
                    old_data_item = slice_prophet(old_data, **filters)
                    new_data_item = slice_prophet(new_data, **filters)
                    all_inputs.append(
                        (old_data_item, new_data_item, new_data_daterange, filters)
                    )

    with Pool(5) as p:
        analyzers = p.map(_get_fit_analyzer, all_inputs)

    return analyzers


def make_model(training_data):
    """
    Initialize and train Prophet model using training data

    :param training_data: Dataframe of metric values with columns `ds` and `y`
    :return: Prophet model to predict with
    """
    m = Prophet(
        daily_seasonality=False,
        yearly_seasonality=False,
        interval_width=1,
        changepoint_range=1,
    )
    m.fit(training_data)
    return m


def get_deviations(predictions, actuals, interval_multiplier=1.5):
    """
    Compute deviations of actuals from forecasts

    :param predictions: Dataframe of forecasted values generated by Prophet model
    :param actuals: Dataframe of true values, containing columns `ds` and `y`
    :param interval_multiplier: Coefficient to multiply width of allowed interval.
    Lower means more sensitive. Default = 1.5
    :return: Dataframe of all observations indicating their status
    (`ok`, `missing`, `above`, `below`).
    """

    def get_adjusted_bound(x, x_bound):
        return x + (x_bound - x) * interval_multiplier

    def get_status(d):
        return np.where(
            d["y"].isna(),
            "missing",
            np.where(d["above"], "above", np.where(d["below"], "below", "ok")),
        )

    return (
        predictions.join(actuals.set_index("ds"), on="ds")
        .assign(
            upper_bound=lambda d: get_adjusted_bound(d["yhat"], d["yhat_upper"]),
            lower_bound=lambda d: get_adjusted_bound(d["yhat"], d["yhat_lower"]),
            above=lambda d: d["y"] > d["upper_bound"],
            below=lambda d: d["y"] < d["lower_bound"],
            status=get_status,
        )
        .sort_values("ds")[["ds", "y", "status", "yhat", "upper_bound", "lower_bound"]]
    )


def get_last_reliable_date(data):
    """
    Find last date in dataset we can reliably check for

    Since data suppliers don't deliver all data at once, we adjust
    the checks to account for it. Namely, if data from Goat is in the dataset,
    we will only check deviations until two days before day we received data
    from them.
    :param data: Full input dataframe
    :return: Latest date to check
    """
    goat_data = data.loc[lambda d: (d["dimension"] == "vendor") & (d["item"] == "goat")]
    if len(goat_data) > 0:
        return goat_data["ds"].max() - timedelta(days=2)
    else:
        return data["ds"].max()


def prepare(data, reference_date, dates_to_exclude):
    """
    Split data into training and prediction set

    Training set: period of one year preceding reference date, excluding specified dates.

    :param data: Dataframe of daily metrics
    :param reference_date: Date for split between training and predictions
    :param dates_to_exclude: Which dates to exclude from training set
    :return: Tuple of Dataframes for training set and prediction set
    """
    data = data.assign(ds=lambda d: pd.to_datetime(d["date"]))
    reference_date = pd.to_datetime(reference_date)
    old_data = data.loc[
        lambda d: (d["ds"] < reference_date)
        & ~d["ds"].isin(dates_to_exclude)
        & (d["ds"] >= reference_date - timedelta(days=365))
    ]
    last_reliable_date = get_last_reliable_date(
        data.loc[lambda d: d["ds"] >= reference_date]
    )
    new_data = data.loc[lambda d: d["ds"].between(reference_date, last_reliable_date)]

    return old_data, new_data


def subset_exists(data, metric, dimension, item):
    """
    Check if subset of selected parameters exists in given table
    :param data: Dataframe
    :param metric: Selected metric
    :param dimension: Selected dimension
    :param item: Selected item
    :return: Boolean indicating presence of parameters
    """
    return (
        (metric in data.columns)
        and (dimension in data["dimension"].unique())
        and (item in data["item"].unique())
    )


def create_daterange_df(new_data, date_column="ds"):
    """
    Create a Dataframe with a date range covering whole period
    :param new_data: Prediction Dataframe
    :param date_column: Column with date information
    :return: Dataframe with column `ds` spanning over whole period
    """
    return pd.DataFrame(
        {
            "ds": pd.date_range(
                new_data[date_column].min(), new_data[date_column].max(), freq="D"
            )
        }
    )


def slice_prophet(
    data, dimension="vendor", item="goat", metric="n_lines",
):
    """
    Slice data and transform to format used by Prophet

    :param data: Input dataframe
    :param dimension: Dimension
    :param item: Item
    :param metric: Metric
    :return: Dataframe for Prophet model
    """
    return data.rename(columns={metric: "y"}).loc[
        lambda d: (d["dimension"] == dimension) & (d["item"] == item)
    ]


def create_chart(old_data, new_data, deviations, metadata):
    fig, ax = plt.subplots(figsize=(15, 5))
    ax.plot(old_data.sort_values("ds")["ds"], old_data.sort_values("ds")["y"])
    ax.scatter(old_data.sort_values("ds")["ds"], old_data.sort_values("ds")["y"])
    ax.fill_between(
        deviations["ds"],
        deviations["lower_bound"],
        deviations["upper_bound"],
        alpha=0.2,
    )
    ax.plot(deviations["ds"], deviations["yhat"], "--", alpha=0.5)
    ax.scatter(new_data["ds"], new_data["y"], c="red")
    ax.set_ylabel(metadata["metric"])
    ax.set_xlabel("Date")
    ax.set_xlim(left=old_data["ds"].max() - timedelta(days=60))
    ax.set_title(f"Predictions for {metadata['dimension']} / {metadata['item']}")
    return fig


def _get_fit_analyzer(x):
    a = Analyzer(*x)
    a.find_deviations()
    return a
